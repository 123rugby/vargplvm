\section{Conclusions \label{conclusions}}
%% Many applications in computer vision and related fields are concerned
%% with modelling in scenarios where multiple streams of information of
%% the same underlying phenomenon are available. Further, the data is
%% often very high dimensional with enormous redundancies.
%Such a representation often means that the data
%is distributed on or close to a manifold through the observed
%parametrization.  
We have presented a new factorized latent variable model for multi
view data.  The model automatically factorizes the data using
variables representing variance that exists in each view separately
from variance being specific to a particular view. 
%% that automatically factorizes the latent space into variables that
%% are either shared or specific to one of the views of the
%% data.
% We introduced a relaxation to the discrete segmentation
%% of the latent representation 
% and allow for a ``softly'' shared latent space.
%The model learns the structure of the latent space variationally,
% allowing it to incorporate prior distributions for the latent space. 
The model learns a distribution over the latent points
variationally. This allows us to to automatically find the
dimensionality of the latent space as well as to incorporate prior
knowledge about its structure.
%
As an example, we showed how dynamical priors can be included on the latent
space. This allowed us to use temporal continuity to disambiguate the
model's predictions in an ambiguous human pose estimation problem.
%
%We exploited the factorization to perform human
%pose estimation in an ambiguous setting.
% where the model separates the variance in the pose
%space that can be determined from the image observations from the one
%that is ambiguous. 
% Our model allows for dynamical priors to be
% incorporated when learning it. This allowed us to disambiguate
% in the pose estimation example. 
%
The model is capable of learning from extremely high-dimensional
data. We illustrated this by learning a model directly on the pixel
representation of an image. Our model is capable of learning a compact
an intuitive representation of such data which we exemplified by
generating novel images by sampling from the latent representation in a
structured manner.
%% applying it to images of several different
%% faces under the same set of lighting conditions. Images of faces from
%% novel lighting directions or with novel appearance could be
%% synthesized by sampling from the corresponding latent space.
%
%The model is capable of learning from
%extremely high-dimensional data. By applying it to images of
%several different faces under the same set of lighting conditions the model
%correctly finds the generating low-dimensional parameters of the data
%separated into facial appearance and illumination direction. From the
%resulting model we showed how images of faces from novel lighting
%directions or with novel facial characteristics could be synthesized.
%
%
Finally, we showed how a generative model with discriminative
capabilities can be obtained by treating the observations and class labels
of a dataset as separate modalities.  

% As future work, we envisage
% approaches with more sophisticated ways of directly constraining the
% latent space through priors. 
% %In classification scenarios, for
% %example, we could consider a latent space prior evaluated at the class
% %labels.
%  Further, it would be interesting to explore the possibility of
% incorporating different latent space constraints for each different
% observed modality.


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../svargplvmICML2012"
%%% End: 
