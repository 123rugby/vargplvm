Observations in Computer Vision are often extremely
high-dimensional. However, the dimensionality of the representation typically
does not reflect the intrinsic dimensionality of the data but is rather an effect of
the system that has acquired it. A central problem is finding
a new more efficient representation in order to circumvent
the \emph{curse of dimensionality} \cite{bellman1957dynamic}. Given a
set of data, a large range of dimensionality reduction approaches have
been suggested ranging from spectral methods, often based on
Multi-Dimensional Scaling \cite{Cox:2008uv}, to generative methods such
as GTM \cite{Bishop:1998fl}. The generative approaches build models
of the data and are in general founded on more sound principles, making
less restrictive assumptions about the data \cite{Ek:2009vv}. The
benefit of spectral methods is that they are 
convex and can be more efficient at handling large datasets.
%generally more efficient 
%in
%capable of
% handling large amounts of data in high dimensions.

In many application scenarios we have access to several different
observation modalities of a single underlying phenomenon. This could
be colour and depth images depicting the same scene or simultaneous
visual and audio recordings from a meeting room.  Given such data it
would be beneficial to represent each modality within the same
model. This would allow us to reason about the whole when only a
subset of the modalities are available. It could also be exploited as
a means of transferring from one modality to another.

Several 
%algorithms that marry the two different features explainedabove have been presented over the years.
approaches for combining these multiple views have been presented. 
Spectral models have often
been motivated by finding low-dimensional representations using
transformations of the observations based on correlation
\cite{Kuss:2003wp}, such as \cite{Ham:2005vs}, or mutual information
\cite{Memisevic:2011tq}. However, such approaches encode only a
subset of the variance and do not provide a probabilistic model. To that end,
several different generative models have been suggested.
In particular, % Of such \textcolor{red}{????}
generative approaches formulated as Gaussian Processes Latent Variable Models
(GP-LVMs) \cite{Lawrence:2005vk} have been especially successful
\cite{Shon:2006wr,Ek:2007uo}.
 However, these models make the
assumption that all the variance in the observations is shared while
the non-shared proportion of the data should be explained away as
noise. This severely limits the applicability of the
model. To overcome this, the idea of a factorized latent space was
presented in \cite{Ek:2008up} where each observation space is
associated with a \emph{private} space, representing the variance which
cannot be explained from the other observation spaces in addition to
the shared space \cite{Ek:2009vv}.

The idea of organizing the data into a structure that separately
represents shared and private variance is very appealing as it allows
a principled model of ambiguities in the data
\cite{Ek:2008up}. However, these models are very sensitive to
initialization meaning that the factorization needs to be
specified. Further, the dimensionality of the latent representation
can not be learned within the model but has to be specified a
priori. To overcome such problems, also regularizers such as
\cite{Salzmann:2010vh} were developed and allow both the
factorization and the dimensionality to be learned. However, these
regularizers were motivated out of necessity rather than principle and
add additional parameters to the model.

In this paper we present a new principled model capable of learning a
factorized latent variable representation of multiple observation
spaces. The approach overcomes and addresses each of the issues
presented above. It learns an efficient low dimensional representation
of the data in a principled manner based on Gaussian
Processes. In contrast to previous approaches the model is fully
Bayesian, capable of learning both the dimensionality and the
structure of the latent representation. Further, the proposed model is
capable of handling extremely high dimensional data, such as directly
learning a latent variable representation of the pixel space of an image dataset.

In the remainder of the paper, we define our model in detail in section \ref{model},
and in section \ref{experiments} we describe the experiments conducted on high dimensional image data and on
a multi-modal human pose dataset. Based on the results and the analysis performed there, we
present our final conclusions in section \ref{conclusions}.