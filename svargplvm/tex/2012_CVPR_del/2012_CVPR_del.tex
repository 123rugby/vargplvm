\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{subfigure}
\usepackage[usenames,dvipsnames]{color}
\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

%\usepackage{tikz}
%\usetikzlibrary{arrows,fit,shapes,automata,topaths,petri}
%\usetikzlibrary{decorations.pathreplacing,decorations.pathmorphing,calc,backgrounds,fit,plotmarks}
%\usetikzlibrary{positioning}

% \cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{1798} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\ifcvprfinal\pagestyle{empty}\fi
\begin{document}

\newcommand{\highlight}[1]{\colorbox{yellow}{#1}}

\newcommand{\bff}{\mathbf{f}}
\newcommand{\bfu}{\mathbf{u}}
\newcommand{\bfy}{\mathbf{y}}
\newcommand{\bfx}{\mathbf{x}}
\newcommand{\bft}{\mathbf{t}}
\newcommand{\bfk}{\mathbf{k}}
\newcommand{\bfzi}{\mathbf{z}}
\newcommand{\bfw}{\mathbf{w}}
\newcommand{\bfmu}{\boldsymbol \mu}
\newcommand{\bfz}{\mathbf{0}}
\newcommand{\bftheta}{\boldsymbol \theta}

\newcommand{\T}{{\top}}

\newcommand{\bfa}{\mathbf{a}}
\newcommand{\bb}{\beta^{-1}}
\newcommand{\la}{\left\langle}
\newcommand{\ra}{\right\rangle}
\newcommand{\vv}{\vartheta}

\newcommand{\intd}{\text{d}}


\title{Manifold Relevance Determination}

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\small\url{http://www.author.org/~second}}
}

\maketitle
% \thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
  In this paper we present a fully Bayesian latent variable model
  which exploits conditional non-linear (in)-dependence structures to
  learn an efficient latent representation. The model is capable of
  learning from extremely high-dimensional data and is directly
  applied to image observations. The latent representation is
  efficiently factorized and separately represents shared and private
  information from multiple views of the data. We can exploit this
  factorization, for example, to perform multi-modal estimation of human
  pose. Being capable of incorporating additional priors in the latent space, we can 
  perform disambiguation in a
  principled manner by learning a
  representation that reflects the dynamic structure in the
  data. Further, we exemplify the generative capabilities of the model
  by learning a low-dimensional representation of a set of facial
  images under different illumination conditions. The model correctly
  factorizes the direction of light from the appearance of the face
  and is capable of generating new images from novel light directions.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
\input{includes/introduction.tex}

\input{includes/model2.tex}

\input{includes/experiments.tex}

\input{includes/conclusions.tex}


{\small
\bibliographystyle{ieee}
\bibliography{2012_CVPR_del}
}


\end{document}
